# üöÄ TALE FORGE AI PIPELINE ARCHITECTURE

## üéØ **CORE AI SERVICES (NEVER CHANGE)**

### **TEXT GENERATION:**
1. **PRIMARY:** GPT-4o (OpenAI) 
2. **FALLBACK:** Meta-Llama-3.3-70B-Instruct (OVH)

### **IMAGE GENERATION:**
- **ALWAYS:** Stable Diffusion XL (OVH SDXL) - NO ALTERNATIVES

---

## üìä **FUNCTION HIERARCHY**

### **CORE AI PIPELINE FUNCTIONS:**
- `generate-story-segment` - Main story/text generation (GPT-4o ‚Üí Llama-3.3) ‚≠ê
- `generate-story-ending` - Story conclusions (GPT-4o ‚Üí Llama-3.3) ‚≠ê
- `regenerate-image` - Image regeneration (OVH SDXL ALWAYS) ‚≠ê
- `generate-story-image` - Initial image generation (OVH SDXL ALWAYS) ‚≠ê

### **UTILITY AI FUNCTIONS:**
- `regenerate-seeds` - Prompt generation (GPT-4o ‚Üí Llama-3.3)
- `generate-audio` - Text-to-speech (OVH TTS)

### **ORCHESTRATION FUNCTIONS:**
- `create-story` - Orchestrates story creation + calls generate-story-segment
- `get-story` - Retrieves story data (no AI, field mapping)

---

## üîß **CONFIGURATION LOCATIONS:**

### **Main AI Config:**
`supabase/functions/generate-story-segment/config/ai-config.ts`
```typescript
OPENAI_CONFIG: { model: 'gpt-4o' }      // PRIMARY
OVH_AI_CONFIG: { model: 'Meta-Llama-3_3-70B-Instruct' }  // FALLBACK
```

### **Image Generation:**
`supabase/functions/generate-story-image/index.ts`
```typescript
SDXL_CONFIG: { baseUrl: 'stable-diffusion-xl.endpoints...' }  // ALWAYS
```

---

## ‚ö° **EXECUTION FLOW:**

1. **User creates story** ‚Üí `create-story` function
2. **create-story calls** ‚Üí `generate-story-segment` (first segment)
3. **generate-story-segment** tries GPT-4o ‚Üí falls back to Llama-3.3 if needed
4. **Images generated by** ‚Üí `generate-story-image` (OVH SDXL always)
5. **User makes choice** ‚Üí `generate-story-segment` (next segment)

---

## üö® **CRITICAL RULES:**

1. **NEVER CHANGE:** Image generation must ALWAYS use OVH SDXL
2. **TEXT PRIORITY:** GPT-4o first, Llama-3.3 second, no other providers
3. **NO HARDCODING:** All AI calls must have proper fallback logic
4. **CONSISTENCY:** All functions must use same model versions

---

## üîç **MONITORING:**

The AI provider status is logged in each function:
```
üîç AI Provider Status: { hasOpenAI: true, hasOVH: true, primaryProvider: 'OpenAI' }
```

**If both providers fail:** Development mode creates placeholder content with clear messaging.

---

## üéØ **DEPLOYMENT STATUS:**

‚úÖ **CORRECTLY CONFIGURED:**
- generate-story-segment (main AI pipeline)
- generate-story-image (OVH SDXL)
- create-story (orchestration)
- get-story (data retrieval)

‚úÖ **RECENTLY FIXED:**
- generate-story-ending (was using gpt-4o-mini, now gpt-4o)
- regenerate-seeds (was OpenAI-only, now has OVH fallback)

---

**‚ö†Ô∏è NEVER MODIFY THIS ARCHITECTURE WITHOUT UPDATING THIS DOCUMENT ‚ö†Ô∏è**